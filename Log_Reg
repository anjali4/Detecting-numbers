import numpy as np
import pandas as pd

##softmax
def softmax(u):
  expu=np.exp(u)
  return expu/np.sum(expu)

##cross entropy loss func
def crossEntropy(p,q):
  return -np.vdot(p,np.log(q))

##cost evaluation
def eval_L(X,Y,beta):
  N=X.shape[0]
  L=0.0
  for i in range(N):
    XiHat=X[i] ##augmented feature vector
    Yi=Y[i] ##ground truth
    qi=softmax(beta @ XiHat) ##probability vector

    L+=crossEntropy(Yi,qi) ##loss for each i

  return L

##logisticregression function(stochastic)
def logReg_SGD(X,Y,alpha):
  numEpochs=5 ##epochs defined
  N,d = X.shape   ##N=n_samples,d=n_features
  X=np.insert(X,0,1,axis=1)
  k=Y.shape[1]
  beta=np.zeros((k,d+1))
  Lvals=[]
  for ep in range(numEpochs):

    L=eval_L(X,Y,beta)
    Lvals.append(L)

    print("Epoch is: "+str(ep)+" Cost is:"+str(L))

    prm=np.random.permutation(N) ##random values chosen to perform stochastic gradient descent
    for i in prm:
      XiHat=X[i]
      Yi=Y[i]

      qi=softmax(beta @ XiHat)
      grad_Li=np.outer(qi-Yi,XiHat)

      beta -= alpha*grad_Li

    return beta,Lvals

##predictor
def predict(X,beta):
  X=np.insert(X,0,1,axis=1)
  N=X.shape[0]

  predictions=[]
  for i in range (N):
    XiHat=X[i]
    qi=softmax(beta @ XiHat)

    p=np.argmax(qi)

    predictions.append(p)

  return predictions

train=pd.read_csv('sample_data/mnist_train_small.csv')
test=pd.read_csv('sample_data/mnist_test.csv')

df = pd.DataFrame(train)

dff = pd.DataFrame(test)

##extracting y out of dataset
Y_train=df.iloc[:,0]
Y_test=dff.iloc[:,0]

##extracting x out of dataset
X_train=df.drop(df.columns[0], axis=1)
X_test=dff.drop(dff.columns[0], axis=1)


##converting dataframe to numpy array
X_train.to_numpy()
X_test.to_numpy()
Y_train.to_numpy().astype('int')
Y_test.to_numpy().astype('int')  

X_train = X_train/255.0
X_test = X_test/255.0

X_train=X_train.values
X_test=X_test.values

Y_train = pd.get_dummies(Y_train).values ## converts to one_hot

##returns parameters and loss from gradient descent
alpha = 0.01
beta, Lvals= logReg_SGD(X_train, Y_train, alpha)

N_test = X_test.shape[0]
X_test = np.reshape(X_test,(N_test,28*28))
predictions = predict(X_test, beta)

numCorrect = 0
for i in range(9999):

    if predictions[i] == Y_test[i]:
      numCorrect += 1

accuracy = numCorrect/N_test
print('accuracy: '+ str(accuracy))
